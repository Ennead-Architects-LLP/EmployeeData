# Simplified Scraper Architecture

## ğŸ¯ **Single Flow Design**

The scraper now follows a **single, unified flow** that works for both local development and GitHub Actions.

## ğŸ“‹ **Architecture Overview**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   main.py       â”‚    â”‚ ScraperOrchestrator â”‚    â”‚ UnifiedScraper  â”‚
â”‚ (Entry Point)   â”‚â”€â”€â”€â–¶â”‚   (Single Flow)   â”‚â”€â”€â”€â–¶â”‚ (Data Extraction)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                        â”‚                        â”‚
         â–¼                        â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ weekly_scraper.pyâ”‚    â”‚   JSON Files     â”‚    â”‚   Images        â”‚
â”‚ (GitHub Actions)â”‚    â”‚   (Individual)   â”‚    â”‚   (Profile)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ **Components**

### 1. **`main.py`** - Single Entry Point
- **Purpose**: Main entry point for both local and GitHub Actions
- **Features**: 
  - Command-line argument parsing
  - Configuration management
  - Debug mode support
  - Credential setup

### 2. **`ScraperOrchestrator`** - Single Orchestrator
- **Purpose**: Orchestrates the entire scraping process
- **Features**:
  - Scrapes employee data using UnifiedScraper
  - Saves individual JSON files to `docs/assets/individual_employees/`
  - Saves combined JSON file to `docs/assets/employee_files_list.json`
  - Downloads images to `docs/assets/images/`

### 3. **`UnifiedScraper`** - Core Scraper
- **Purpose**: Extracts comprehensive employee data
- **Features**:
  - Browser automation with Playwright
  - Authentication handling
  - Comprehensive data extraction
  - Image downloading

### 4. **`weekly_scraper.py`** - GitHub Actions Wrapper
- **Purpose**: Simple wrapper that calls `main.py`
- **Features**:
  - Calls `python -m src.main --headless=true`
  - Handles logging and error reporting
  - No duplicate logic

## ğŸš€ **Usage**

### Local Development
```bash
cd 2-scraper
python -m src.main
```

### GitHub Actions
```bash
cd 2-scraper
python weekly_scraper.py
# Which internally calls: python -m src.main --headless=true
```

## ğŸ“ **Output Structure**

```
docs/assets/
â”œâ”€â”€ individual_employees/       # Individual JSON files
â”‚   â”œâ”€â”€ John_Doe.json
â”‚   â”œâ”€â”€ Jane_Smith.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ images/                     # Profile images
â”‚   â”œâ”€â”€ John_Doe_profile.jpg
â”‚   â”œâ”€â”€ Jane_Smith_profile.jpg
â”‚   â””â”€â”€ ...
â””â”€â”€ employee_files_list.json    # Combined employee data
```

## âœ… **Benefits**

1. **Single Source of Truth**: One scraper, one orchestrator, one flow
2. **No Duplication**: Same logic for local and GitHub Actions
3. **Clear Separation**: Scraper only scrapes, no HTML generation
4. **Simple Maintenance**: Changes in one place affect everything
5. **Consistent Output**: Same JSON structure everywhere
6. **Easy Testing**: Single entry point for all testing

## ğŸ¯ **What Was Removed**

- âŒ **HTML Generation**: Moved to static framework in docs folder
- âŒ **Voice Announcements**: Not needed for automated scraping
- âŒ **Multiple Orchestrators**: Consolidated to single ScraperOrchestrator
- âŒ **Development vs Production**: Single flow for all use cases
- âŒ **Complex Mode Logic**: Simplified to single comprehensive scraper

## ğŸ”„ **Migration**

### Before (Complex)
- `DevelopmentOrchestrator` + `ProductionOrchestrator`
- HTML generation + voice announcements
- Different flows for local vs GitHub Actions

### After (Simple)
- `ScraperOrchestrator` (single orchestrator)
- JSON files only (no HTML generation)
- `weekly_scraper.py` just calls `main.py`

## ğŸš€ **Future Enhancements**

- Add configuration options for different output formats
- Add more specialized scrapers if needed
- Consider making the orchestrator more configurable
- Add more comprehensive error handling and retry logic

This simplified architecture makes the scraper much easier to understand, maintain, and extend!
